\section{Results and Discussion} \label{sec:results}

This section reports annotate-and-reconstruct experiments comparing phylogeny reconstruction quality obtained across possible hereditary stratigraphy approaches.
We delve into two primary aspects of hereditary stratigraphy methodology:
\begin{enumerate}
\item surface- versus column-based implementation and
\item tilted versus steady (versus hybrid) retention.
\end{enumerate}

We find that surface-based implementation tends to improve reconstruction quality under tilted retention, with tilted retention matching or outperforming steady retention across evolutionary scenarios --- except under drift conditions, where phylogenetic richness is very high.

\subsection{Surface vs. Column Implementation} \label{sec:surface-vs-column}

\input{fig/col-vs-surf-summary}

Recall that surface- and column-based annotation implementations differ in how differentiae are organized within a hereditary stratigraphy annotation.
Surface-based implementation takes a lower-level approach that streamlines generation-to-generation updates and ensures full use of available memory space, but sacrifices some control over the temporal distribution of retained differentiae.
Both implementations support tilted and steady retention policies.

Figure \ref{fig:col-vs-surf-summary} compares reconstruction quality for surface algorithms against their corresponding column implementation.
Outcomes differ notably between tilted and steady retention.

\subsubsection{Surface vs. Column for Tilted Retention}

Under tilted retention, triplet distance (a measure of reconstruction accuracy) significantly improves in $14 / 48$ scenarios under surface-based implementation, before correction for multiple comparisons.
Column-based implementation significantly improves reconstruction accuracy in no scenarios when applying the Mann-Whitney U test.
Looking at effect sizes via Cliff's delta, surface-based approaches improve reconstruction quality with at least a small effect size in $33 / 48$ scenarios.
Column-based approaches improve reconstruction quality with a small effect size in 1 /48 scenarios.
Although no Mann-Whitney U tests from any individual scenario are significant after Bonferroni correction, a strong trend exists \textit{across} scenarios of better reconstruction quality from surface-based implementation for tilted retention (exact Binomial test; $p < 0.0001$).

Inner node loss (a measure of reconstruction precision) significantly improves with surface-based implementation in some scenarios ($24 / 48$), and significantly worsens in others ($13 / 48$).
All results remain significant after correction for multiple comparisons.
Notably, inner node loss improvement under surface-based implementation is seen in all treatments with byte-width differentiae, which are more prone to create artifactual unresolved polytomies that drive inner node loss (Figure \ref{fig:col-vs-surf} in Data \& Materials; \citep{moreno2024supplemental}).
In sum for tilted retention, reconstruction quality of surface-based annotations can be considered equivalent or superior across the board to column-based implementation.

\subsubsection{Surface vs. Column for Steady Retention}

In contrast, under steady retention, surface-based implementation achieves worse triplet distance in $11 / 48$ scenarios and better triplet distance in no scenarios.
Only one Mann-Whitney U test remains significant after Bonferroni correction.
However, a significant trend again exists across scenarios, with $25 / 48$ scenarios where surface-based implementation degrades triplet distance by at least a small effect size under Cliff's delta (exact Binomial test; $p < 0.0001$).

Additionally, for steady retention, inner node loss is significantly worse under surface-based in $23 / 48$ scenarios and better in no scenarios.
So, across the board, reconstruction quality of surface-based annotations under steady retention is equivalent or inferior to that of column-based implementation.

\subsubsection{Surface vs. Column --- Synthesis}

Why does the surface-based approach benefit reconstruction under one retention policy but not the other?
Compared to column-based implementation, surface-based implementation allows the tilted algorithm to retain more differentiae within available annotation space.
Whereas the write-only design of the surface-based approach guarantees full use of buffer space, column-based tilted retention wastes some space held in reserve due to algorithmic limitations.
In contrast, column-based steady retention makes full use of available space, giving the surface-based approach no advantage in this regard.
Although both the surface and column approaches prune differentiae through comparable strided decimation procedures, the column implementation more systematically drops decimated differentiae from back to front.
This process ends up preserving more recent differentiae, which --- as we will see in the next set of experiments --- tends to benefit reconstruction quality.

Although surface-based implementation involves a trade-off between performance and reconstruction quality in the case of steady retention, it is notable that surface-based implementation improves both runtime performance and data quality under tilted retention.
Given this result, we next assess the extent to which tilted or steady retention would be preferred in practice across possible evolutionary scenarios.

% We did this by using a simple simulation to generate phylogenies under different conditions with perfect tracking, then simulating heritage of hstrat annotations down the perfect tree and subsequent reconstruction.
% We could then compare the reconstruction that would have been obtained under approximate tracking to the underlying ground truth.

% To ensure generalizable results, we tested over a large number of evolutionary regimes, population sizes, instrumentation sizes, and instrumentation fingerprint sizes.

% We took three measures of reconstruction quality.
% The first measure, triplet distance, is a measure of accuracy --- it is the fraction of triplet tips that are correctly arranged in the reconstruction.
% Whereas this metric considers polytomies as distinct from separate branching events, our second measure is a lax variant of triplet distance that does not penalize penalties introduced into the reconstruction (i.e., due to uncertainty about branching order) or over-resolution of true polytomies into more nodes in the reconstruction.
% Finally, we also include inner node count, which provides a measure of the amount of precision achieved by reconstructions.
% Higher inner node count indicates that fewer branching events are being lumped together into polytomies due to insufficient information to differentiate them.
% This metric is only applicable to scenarios with fingerprint sizes larger than one bit (i.e., a byte), which are capable of generating non-bifurcating trees.

% The data tell two clear stories:
% \begin{enumerate}
% \item surface tilted algorithms create higher-quality reconstructions than column-based tilted algorithms and
% \item surface column algorithms create lower-quality reconstructions than column-based column algorithms.
% \end{enumerate}

\subsection{Steady vs. Tilted Retention} \label{sec:steady-vs-tilted}

\input{fig/steady-vs-tilted-summary}

Recall that steady and tilted retention differ in the temporal composition of retained differentiae;
steady policy spaces retained differentia evenly across history, while tilted policy biases toward retaining more recent differentiae.
The question of which policy enables higher quality reconstruction boils down to where precision in discerning the timing of lineage branching events is most useful in resolving evolutionary history.
To ensure even footing, we report results for each retention policy using its best-performing implementation, as established above.
Steady policy uses column implementation and tilted policy uses surface-based implementation.
We also consider a surface-based hybrid policy, which splits buffer space evenly between steady and tilted retention.

Figure \ref{fig:steady-vs-tilted-summary} overviews reconstruction quality by retention policy across use case scenarios.
Across the board, steady policy yields phylogenetic reconstruction with heaviest inner node loss.
In contrast, tilted policy exhibits among the lowest inner node loss in all but six surveyed scenarios --- including all byte-differentia trials (Figure \ref{fig:steady-vs-tilted} in Data \& Materials; \citep{moreno2024supplemental}).
The hybrid policy has lower inner node loss in those six scenarios, which all involve evolutionary conditions with high phylogenetic richness.

Steady policy also consistently produces the highest triplet distance error in lower-phylogenetic-richness plain and mild-structure evolutionary scenarios.
However, in scenarios with high phylogenetic richness, triplet distance error under steady retention fares better.
With rich ecological/spatial structure, triplet distance reconstruction error is largely indistinguishable among retention policies.
Further, steady policy triplet error significantly outperforms tilted policy in several instances under drift conditions.
In nearly all of these instances, though, hybrid policy triplet error performs comparably to steady retention.
In low phylogenetic richness plain and mild-structure scenarios, hybrid triplet error is comparable to tilted error in $9 / 24$ scenarios and outperformed by tilted policy in $15 / 24$ scenarios.

Across the inner node loss and triplet error quality measures, tilted retention frequently performs best and steady retention frequently performs worst.
However, tilted retention has worse triplet error in some scenarios with high phylogenetic richness.
Hybrid retention performs more consistently across evolutionary scenarios.
It exhibits consistently intermediate levels of inner node loss that, in absolute terms, tend to be comparable to tilted retention.
Triplet error for hybrid retention is often comparable to the better-performing of steady and tilted retention, or at least intermediate between them.
For greater detail of steady vs. tilted reconstruction quality outcomes broken down by treatment condition, see Supplementary Figure \ref{fig:steady-vs-tilted} \citep{moreno2024supplemental}.

\input{fig/recency-structure}

Differences in retention of recent differentia explain the substantial advantage of tilted policy in evolutionary scenarios with low phylogenetic richness.
In such scenarios, frequent selective sweeps concentrate phylogenetic history over very recent history, meaning that lineage-branching events giving rise to a contemporary extant population occur over a relatively short period of time.
Discerning these events, therefore, requires densely packed differentia checkpoints over recent history.
Otherwise, in the worst case, taxa would jump from all sharing the same lineage marker at one checkpoint to all having distinct checkpoint markers --- resulting in a catastrophic unresolved polytomy.
Steady retention maintains a uniform gap size between retained differentiae that grows linearly with generations elapsed, meaning that very recent history is thinly covered, if at all.
The consequences of this deficiency can be seen in Figure \ref{fig:recency-structure}, which compares the density of reconstructed nodes to ground truth.
Reconstructions from steady policy are entirely missing branching events over the most recent generations, consistent with steady policy's relative sparsity of recent timepoints.
% Figures \labelcref{fig:bit-vs-byte-summary-byte-outcomes,fig:bit-vs-byte-summary-bit-outcomes} show reconstruction outcomes resulting under this inner node loss.
% Under steady policy, very high levels of unresolved reconstruction occur in scenarios with low phylogenetic richness, particularly for recent branching events.
% Example reconstructions exhibiting catastrophic comb polytomies characteristic of steady reconstruction of low-richness phylogenies can be seen in \ref{fig:examplepanel}.

% \subsection{Bit vs. Byte Differentia Width} \label{sec:bit-vs-byte}

% \input{fig/bit-vs-byte-summary}

% We now turn to consider the role of differentia size in hereditary stratigraphy reconstruction quality.
% Intuitively, tuning differentia size would seem to trade-off between accuracy and precision.
% Larger differentiae reduce the probability of spurious collision, which falsely makes lineages appear more closely related than they actually are.
% Note, in particular, that reconstructions from bit-sized differentia estimate all history as bifurcating, because each checkpoint can only discern two distinct lineages.
% On the other hand, for fixed annotation size, widening differentia necessarily reduces differentia count.
% Thus, differentia size diminishes the granularity at which branching events can be dated.

% To ascertain the actual effects of differentia width on reconstruction quality, we performed annotate-and-reconstruct experiments across a variety of use case scenarios.
% These experiments used 256-bit-sized annotations, comprised of either 256-bit-sized differentiae or 32-byte-sized differentiae.
% Figure \ref{fig:bit-vs-byte-summary-quality} overviews the relative performance of bit- and byte-width differentiae on triplet distance and inner node loss quality measures.
% (Supplementary Figure \ref{fig:bit-vs-byte} presents these results in greater detail, showing reconstruction outcomes for each treatment condition surveyed.)
% However, byte-width differentia consistently produces reconstructions with lower inaccuracy --- as measured by lax triplet distance, which does not penalize unresolved reconstruction.
% Byte-width's lower incidence of incorrect reconstruction outcomes is apparent in Figures \labelcref{fig:bit-vs-byte-summary-byte-outcomes,fig:bit-vs-byte-summary-bit-outcomes}, which assess rates of correct, incorrect, and unresolved reconstruction outcomes across evolutionary history.
% Unlike bit-width annotations, byte-width methods produce almost no incorrect reconstruction outcomes.
% However, owing to unresolved byte-width outcomes, bit-width annotations nonetheless have a higher rate of correct outcomes.
% Figure \ref{fig:bit-vs-byte-summary-quality} indeed confirms that, in nearly all cases, bit-width differentiae produce more informative depictions of phylogenetic history, as measured by strict triplet distance.

% \subsection{Reconstruction Quality vs. Phylogeny Scale} \label{sec:scaling}
% \input{fig/scaling-summary}

% The goal of hereditary stratigraphy methods is to empower new frontiers in digital evolution that harness parallel and distributed computing methods to realize scale-dependent experiments tackling phenomena like evolutionary transitions, eco-evolutionary dynamics, and open-endedness \citep{moreno2022exploring,dolson2021digital,channon2019maximum}.
% We also hope it will prove useful in future application-oriented work using massively parallel and distributed computing for evolutionary optimization.
% Given these objectives, the scaling behavior of hereditary stratigraphy is of key concern.
% Here, we consider two aspects of potential scale-up: (1) the number of taxa sampled for phylogenetic reconstruction and (2) the size of the underlying population.
% Experiments test how reconstruction quality fares with changes in scale along both fronts, across a variety of use case scenarios.
% Supplementary Figures \labelcref{fig:dsamp-popsize-scale-hybrid,fig:dsamp-popsize-scale-steady,fig:dsamp-popsize-scale-tilted} detail the use case scenarios surveyed and summarize reconstruction quality outcomes of phylogeny scale-up under each scenario.

% Scaling results for reconstruction accuracy, measured by triplet distance, are promising.
% Under tilted and hybrid policies, triplet distance error is robust across kinds of phylogenetic scaling --- population size, sample size, and both simultaneously.
% Reconstruction accuracy decreases significantly in only one case under the tilted policy.
% Results under the steady policy are more variable, with triplet distance worsening in 7 cases but improving in 11 cases.

% Inner node loss, under hybrid and tilted retention, is generally also robust to population scaling.
% For these policies, inner node loss worsens only in use cases with byte-width differentiae (Supplementary Figures \labelcref{fig:dsamp-popsize-scale-hybrid,fig:dsamp-popsize-scale-tilted}).
% In other cases, inner node loss actually often improves with population scale.
% Sample size scaling, however, tends to aggravate inner node loss --- whether in isolation or in concert with population size scaling.
% As an exception, we do not see inner node loss worsen with larger sample size in some cases with byte-width differentia under tilted and hybrid policies (Supplementary Figures \labelcref{fig:dsamp-popsize-scale-hybrid,fig:dsamp-popsize-scale-tilted}).
% Likewise, inner node loss remains stable for tilted retention under drift conditions (Supplementary Figure \labelcref{fig:dsamp-popsize-scale-tilted}).

\section{A Practicioner's Guide to Hereditary Stratigraphy} \label{sec:synthesis}

This section shifts focus from an analytical, hypothesis-driven framing, as applied in the previous section, to discussion that is instead prescriptive and summative.
The goal here is to synthesize results from reported annotation-and-reconstruct experiments, as well as other work testing and applying hereditary stratigraphy, to provide concrete, action-oriented advice to guide the reader in effectively applying hereditary stratigraphy in their digital evolution experiment, or other use case.

Discussion covers the following questions,
\begin{enumerate}
\item Should I use hereditary stratigraphy or phylogenetic direct tracking?
\item How should I choose appropriate hereditary stratigraphy configuration for my use case?
\item How do I integrate hereditary stratigraphy instrumentation into my digital evolution simulation?
\item How do I work with hereditary stratigraphy annotation data once it is generated?
\end{enumerate}

\subsection{Hereditary Stratigraphy or Direct Tracking?}

If you are not using parallel or distributed computing, direct phylogenetic tracking should usually be preferred due to its capability for perfect record-keeping; likewise, if your simulation uses a centralized controller-worker paradigm.
A tool like Phylotrack (asexual phylogenies; Python/C++), APoGET (sexual phylogenies; C++) or MABE (C++) might be appropriate for your use case \citep{dolson2024phylotrack,bohm2017modular}.
It is also reasonably straightforward to implement phylogeny tracking yourself \citep{moreno2024algorithms}.
However, for serial or centralized simulations there are a few scenarios where reconstruction-based tracking may be useful,
\begin{itemize}
\item resource-constrained runtime environments where memory is scarce or dynamic memory allocation is not supported (e.g., embedded);
\item simulation objectives require hard real-time operations; or
\item \textit{ad hoc} serialization and re-use of agents across simulation runtimes, where maintaining a cohesive global record is difficult or impractical.
\end{itemize}

In simulations employing decentralized parallel and distributed computation, a reconstruction-based approach such as hereditary stratigraphy is more likely to be appropriate.
Compared to perfect tracking in this setting, hereditary stratigraphy provides simpler implementation, lower runtime communication overhead, and greater robustness to data loss.
Note that, if annotation size is not a concern or a low generation count is anticipated, essentially perfect-quality reconstruction can be achieved with hereditary stratigraphy methods.
In this case, one could simply use a retention policy that discards no differentia and a wide enough differentia width to effectively guarantee collisions will not occur (e.g., 32 or 64 bits).
However, in most cases, a compromise between phylogeny approximation and per-genome annotation size will be necessary.
We cover this in the next section.

\subsection{Annotation Configuration}

The following provides step-by-step instruction on selecting appropriate hereditary stratigraphy methods for a given use case.
In order, we cover
\begin{enumerate}
\item determining annotation order of growth,
\item selecting annotation size,
\item selecting differentia width,
\item picking a retention policy, and
\item selecting between column- or surface-based implementation.
\end{enumerate}

Disussion then turns to a handful of special-case topics.

\subsubsection{Annotation Order of Growth}
\textit{Suggested default choice: constant-size annotation.}

In most scenarios, a constant-size annotation will give better runtime performance and ensure fuller use of available memory resources.
However, if you need hard guarantees on absolute or recency-proportional inference quality, an annotation size that scales $\mathcal{O}(n)$ or $\mathcal{O}(log(n))$, respectively, with generational depth will be necessary.
The \textit{hstrat} Python packge provides \texttt{fixed\_resolution\_algo} and  \texttt{recency\_proportional\_resolution\_algo} policies for such cases \citep{moreno2022hstrat}.

\subsubsection{Annotation Size}
\textit{Suggested default choice: 256-bit differentia buffer with 64-bit generation counter.}

Annotation size must compromise between memory-use and communication-bandwidth overhead and quality of reconstructed phylogenies.
In cases where annotation size is not a limiting factor, when using single-bit differentia 256-bit annotation buffers will discern phylogenetic events with about 13\% recency-relative precision (tilted) or 1\% depth-relative precision (steady) through 1 billion generations.
For full-byte differentia, discussed below, an annotation size on the order of kilobits would be very robust.
Where annotation resource use is a limiting factor, a 64-bit annotation buffer can give good results.

In picking annotation size, some consideration should be given to phylogenetic scale of the experimental use case.
Triplet distance (accuracy) appears to be largely stable under surveyed increases in population size and number of taxa sampled for reconstruction
However, loss of inner node loss can increase when increasing reconstruction sample size.
Where this is a concern, annotation size may need to be increased commensurate to intended phylogeny tip count.

Current implementations of surface algorithms are limited to buffer sizes that are even powers of two (i.e., 32, 64, 128, etc.).
Where finer gradations are desired, one possibility would be to consider intermediate differentia sizes.
For instance, storing 3 bit differentia over 32 surface sites would occupy 96 bits.
Alternately, alternating depositions across a collection of surfaces might be considered (e.g., a 32 bit tilted surface and a 16 bit steady surface).
Note, though that this latter option would require some minor implementation customizations akin to those used to create the hybrid surface retention policy \citep{moreno2024hsurf}.
Column algorithms are more flexible in buffer sizing, but in the case of tilted retention make less full use of available buffer space.

Finally, note that, in addition to differentia values, a generation counter will also need to be stored in genomes.
Keep in mind that where working with fixed-width data types, sufficient representational range will be necessary to support the maximum-expected generational depth occuring in simulation.
For most use cases, a 32- or 64-bit counter value will be appropriate.
% \footnote{One possible exception is cases where a global monotonic counter is available and it is desirable to demarcate phylogenetic history in terms of simulation time rather than generations.}

\subsubsection{Differentia Retention Policy}
\textit{Suggested default choice: hybrid retention policy.}

Hybrid retention policy is a good choice where phylodiversity-enhancing factors (ecology, spatial structure, relaxed selection pressure) are expected or expectation is unclear.
For a given use case it often obtains competitive reconstruction quality to the better of steady and tilted policy.
Even where it is outperformed by one of steady or tilted retention, it avoids catastrophic failure modes characteristic, in particular, of steady retention.
On platforms where steady policy implementation (necessary as a component of hybrid policy) is not readily availabie, tilted policy should typically suffice.
If you do not expect strong phylodiversity-enhancing factors (i.e., no ecology, no spatial structure, high seletion pressure), tilted policy can reliably outperform hybrid policy.
In rare cases where phylodiversity-enhancing factors are very strong (e.g., pure drift conditions), a steady policy may be appropriate.

\subsubsection{Differentia Width}
\textit{Suggested default choice: use bit-size differentia.}

Bit-size differentia maximize the fraction of correct reconstruction outcomes, but can also introduce incorrect reconstruction outcomes.
Byte-size differentia have very low incorrect reconstruction outcome rates and can reconstruct true polytomies, but have a larger incidence of unresolved reconstruction oucomes (artifactual polytomies).
This results in bit-size differentia giving more informative reconstructions, as measured by strict triplet distance error.
If you need very strong guarantees against incorrect reconstruction outcomes, an even larger differentia size (32 or even 64 bits) may be appropriate.

\subsubsection{Column vs. Surface Implementation}
\textit{Suggested default choice: surface implementation.}

If you are using dynamic annotation size, you will need a column-based implementation to allow differentia count growth.
Otherwise, for constant annotation size, surface implementations are much more efficient \citep{moreno2024trackable}.
In the case of tilted retention policy, they also give higher-quality reconstructions.
If using steady policy, column implementation gives higher-quality reconstructions but use of surface implementation would be reasonable due to enhanced runtime performance.
Finally, hybrid policy is currently only provided for surface-based implementaiton.

Another factor that might influence this decision is the software platform being designed for.
If packages providing hereditary stratigraphy are not available, surface algorithms are easier to implement owing to only needing to implement one update operation: site selection on the fixed-size surface buffer.

\subsubsection{Special-case topic: lineage tags}
\textit{Suggested default choice: not needed in most cases.}

In scenarios where explicitly differentiating between founding clades is paramount, consider adding a systematically assigned founder ID or randomly generated fixed tag.
This tag would then be used as a first pass to divvy end-state annotations into independent sets before feeding them into separate reconstruction processes.
If several founding lineages persist, with single-bit differentia spurious collisions can make completely-independent clades falsely appear to share an amount of common history.

\subsubsection{Special-case topic: strided updates}
\textit{Suggested default choice: update hereditary stratigraphy annotations every generation.}

For most applications, annotation updates (i.e., appending a new differentia) should correspond directly to generations elapsed.
However, in cases where fine-resolution visibility below a certain level is not useful, annotations may be updated only that often.
For tilted policy, in particular, this approach can help preserve ancient differentia coverage for longer.

\subsubsection{Special-case topic: clock-based updates}
\textit{Suggested default choice: update hereditary stratigraphy on a generational basis, instead.}

In circumstances where time-indexed resolution is preferred or ultrametricity (tips sharing equal branch lengths from root) is important, annotations can be updated on the basis of logical simulation time or even real time rather than generations elapsed.
In this case, annotation updates would be elapsed, as necessary, on parents' annotations to bring them up-to-date to the current simulation time whenever reproduction event occurs.
This may require multiple back-to-back updates if several simulation time clock cycles have elapsed.

\subsubsection{Special-case topic: incorporating trait data}
\textit{Suggested default choice: collect ``fossil'' phenotypes instead.}

It is possible to ``annotate'' differentia with information about genetic or phenotypic traits associated with corresponding ancestors.
Conveniently, because every internal node in a hereditary stratigraphy reconstruction corresponds to a retained differentia, this approach ensures all internal nodes in a reconstructed phylogeny can be associated to a trait.
However, a similar result can be had by saving out sample ``fossil'' specimens (with corresponding trait information) over the course of a simulation.
Because, like extant taxa, these fossils are associated to hereditary stratigraphy annotations they can readily be incorporated into phylogenetic reconstruction to shed light on ancestral states over history.
This avoids bloating annotation sizes with dozens of trait values on each genome.

\subsection{Runtime Integration}

Three major steps will be necessary to be implemented to run the hereditary stratigraphy pipeline: (1) integration of instrumentation into the simulation runtime genome model, (2) serialization of evolved agents' markers from simulation, (3) loading data into the Python \textit{hstrat} library in order to analyze it.

\begin{itemize}
\item \textbf{Runtime Annotations}:
You will need to augment the \texttt{Genome} data structure in your simulation code in two ways: (1) to store hereditary stratigraphic annotation data and (2) add a call to the copy/reproduce or mutate function to update the differentia store and bump the generation counter.

For sufaces, two components are required: a fixed-buffer differentia store and a generation counter.
The differentia store can be implemented as an array of integer data types (e.g., \texttt{uint8}), but for bit differentia you will likely want to use a raw memory array or an abstraction around it if available (e.g., \texttt{std::bitset}).

Surfaces also have a simple update procedure.
Call \texttt{pick\_deposition\_site} and randomize the differentia element at the returned nth position.

Software implementing column-based approaches is available for Python \citep{moreno2022hstrat} and surface-based approaches are available for Python \citep{TODO}, and Zig/Cerebras Software Language \citep{TODO}.
Based on community feedback, C/C++ and Rust are priority targets to port hstrat surface implementations to.

If you are using another software language, porting core algorithms should be doable with moderate effort.
Are implemented primarily as a library of small functions ($\approx<30$ LOC) with accompanying tests, making them amenable to stepping-stone piece by piece transliteration.
We found LLM assistance to be highly effective in translating the surface algorithms from Python to Zig \citep{TODO}.
Feel free to get in touch --- we would be happy to furnish these algorithms in other languages if you have a use case.
\end{itemize}

\subsection{Postprocessing and Analysis}
\begin{itemize}
\item \textbf{Serialization}
In order to transfer marker data for postprocessing, you will need to save it to file.
For best compatibility with the analysis pipeline, extract annotations and save them together in a conventional format separate from other genome components (e.g., JSON, CSV).
For each annotaiton, you will need to store the generation counter and the differentia data.
One convenient plain text way to encode differentia data is as a hex string.

In order to conduct postprocessing, you will need to use tools in the \textit{hstrat} library.
When reserializing the data, you will need to know the 11¡retention policy and differentia width used so make sure these are recorded somewhere.
Functions to convert raw data into intantiated \texttt{Column} objects are described in package documentation and examples, with a variety of entry points compatible with JSON, YAML, and CSV formats.

Note that, while the hstrat library also provides support to deserialize from compact binary formats in many circumstances, storage in plain text format with zipping (e.g., gzip) will provide competitive --- if not better --- space efficiency to binary representations and can be considerably easier to work with.

\item \textbf{Analysis}
Reconstruction algorithms are currently implemented in the \textit{hstrat} library.
This algorithm takes a list of deserialized column objects and produces a phylogeny.
Optionally, a list of taxa identifiers may also be provided if desired.
A variety of tools for estimation of MRCA between marker pairs or groups are also provided.
Reconstructions are reported in alife community data standard format \citep{TODO}.
Tools are provided that can convert these formats to standard bioinformatics formats for interoperation with the rich existing software ecosystem for phylogenetic visualization and analysis \citep{TODOalifedataphyloinformaticsconvert}.
\end{itemize}
